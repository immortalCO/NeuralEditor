{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ee5AtQTi-v89",
        "2-g63f6b2DvN",
        "oCwdFkq2-i-q",
        "2l9QquTj2FwR",
        "qdRZFuB-3on2",
        "7us8MfsE3qcE",
        "m493V1SEoe5D",
        "juxcxGkInWub",
        "oLtuK2ux2sJw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "SCENE = \"mic\"\n",
        "VER = \"1027\"\n",
        "DEFORM = f\"{SCENE}\"\n",
        "eval_only = True"
      ],
      "metadata": {
        "id": "ZlFU4yL_jESh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # DEBUG ONLY, MUST BE REMOVED\n",
        "# import os\n",
        "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
      ],
      "metadata": {
        "id": "VyZC68Y5xRlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "ee5AtQTi-v89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        already_run_flag\n",
        "    except:\n",
        "        break\n",
        "    assert False, \"Run twice\"\n",
        "\n",
        "already_run_flag = True"
      ],
      "metadata": {
        "id": "F_lOCzZita2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ProjectNerf"
      ],
      "metadata": {
        "id": "z8X2Vk1iT3aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "NBjL7Tvm9Qhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from tqdm import tqdm\n",
        "from tqdm.contrib.logging import logging_redirect_tqdm\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "formatter = logging.Formatter(\n",
        "    '%(asctime)s - %(levelname)s:\\t%(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "fh = logging.FileHandler(f\"scratch/train_field.log\")\n",
        "fh.setLevel(logging.INFO)\n",
        "fh.setFormatter(formatter)\n",
        "\n",
        "ch = logging.StreamHandler()\n",
        "ch.setLevel(logging.DEBUG)\n",
        "ch.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(ch)\n",
        "logger.addHandler(fh)\n",
        "logging.info(\"Init\")"
      ],
      "metadata": {
        "id": "4Tdx6IRrLYoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "id": "OqRY3xa_wdVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import random\n",
        "import open3d as o3d\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "WR0PGJaGBjeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import transforms\n",
        "import cv2\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "import scipy\n",
        "import scipy.linalg\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "owcxoL5-AIc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd cppext"
      ],
      "metadata": {
        "id": "it4D5E-iiwFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup.py install"
      ],
      "metadata": {
        "id": "wmGcp3tVizC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "id": "AewpUbu-jQBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ],
      "metadata": {
        "id": "2-g63f6b2DvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = f\"./datasets/Scratch/ns_{SCENE}\"\n",
        "CLOUD_NAME = \"cloud_pn\"\n",
        "# CLOUD_NAME = \"cloud_pn_aftergrow\"\n",
        "# CLOUD_NAME = \"cloud_gt\"\n",
        "LIGHT_IND = 3\n",
        "CLOUD_SCALE = 1 / 1\n",
        "IMAGE_SCALE = 1\n",
        "IMAGE_SCALE_TRAIN = 1 #7\n",
        "IMAGE_PATCH_TRAIN = 1\n",
        "TRAIN_RANDOM_AUG = False # True\n",
        "TRAIN_REPEAT = 1\n",
        "NUM_PTS = 2**22 if CLOUD_NAME == \"cloud_gt\" else 2**21\n",
        "BORDER_FIX_KER = 0\n",
        "BORDER_FIX_THRES = 8\n",
        "DEFAULT_POV = 0\n",
        "EVAL_MASK_ONLY = False\n",
        "BG_COLOR = [0, 0, 0]\n",
        "IMAGE_TRAIN_BG_PAD = 6\n",
        "NORM_MESH_PARAM = o3d.geometry.KDTreeSearchParamHybrid(radius=0.05, max_nn=512)\n",
        "\n",
        "\n",
        "import json\n",
        "train_config = json.load(open(f\"{DATASET}/transforms_train.json\"))\n",
        "grow_extra_config = None #json.load(open(f\"{DATASET}/transforms_val.json\"))\n",
        "prune_extra_config = json.load(open(f\"{DATASET}/transforms_val.json\"))\n",
        "# valid_config = json.load(open(f\"{DATASET}/transforms_val.json\"))\n",
        "valid_config = json.load(open(f\"{DATASET}/transforms_test.json\"))\n",
        "\n",
        "DEFAULT_VIEW_DIR = [-1., -1., -1.]\n",
        "\n",
        "TRI_EXTEND = False\n",
        "\n",
        "IGNORE_CONF = False if \"aftergrow\" not in CLOUD_NAME else True #True # if CLOUD_NAME == \"cloud_gt\" else False\n",
        "IGNORE_EMBED = True if CLOUD_NAME == \"cloud_gt\" else False\n"
      ],
      "metadata": {
        "id": "3lzV2mH2-pxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Cloud"
      ],
      "metadata": {
        "id": "oCwdFkq2-i-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pth = torch.load(f\"{DATASET}/{CLOUD_NAME}.pth\")\n",
        "pth.keys()"
      ],
      "metadata": {
        "id": "GcocNdroeBSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pts = pth['points_with_color'].float().cpu()\n",
        "pts_conf = pth['confidence'].float().cpu()\n",
        "pts_embed = pth['feature'].float().cpu()\n",
        "pts.shape, pts_conf.shape, pts_embed.shape"
      ],
      "metadata": {
        "id": "DWfFtN-QeM6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extend_pts(pts, N, features=[]):\n",
        "    import scipy\n",
        "    import scipy.spatial\n",
        "    tri = torch.from_numpy(scipy.spatial.Delaunay(pts.numpy()).simplices)\n",
        "    pair = []\n",
        "    for i in range(4):\n",
        "        for j in range(i):\n",
        "            pair.append(tri[:, [i, j]])\n",
        "\n",
        "    pair = torch.cat(pair, dim=0).long()\n",
        "\n",
        "    dist = (pts[pair[:, 0]] - pts[pair[:, 1]]).norm(dim=-1)\n",
        "    mean = dist.mean()\n",
        "    std = dist.std()\n",
        "    mask = dist < mean + 2 * std\n",
        "    pair = pair[mask]\n",
        "\n",
        "    cho = torch.randint(low=0, high=pair.shape[0], size=[N - pts.shape[0]])\n",
        "    coef = torch.rand([N - pts.shape[0], 1])\n",
        "    a = pair[cho, 0]\n",
        "    b = pair[cho, 1]\n",
        "\n",
        "    new_pts = pts[a] * coef + pts[b] * (1 - coef)\n",
        "    new_pts = torch.cat([pts, new_pts], dim=0)\n",
        "\n",
        "    new_features = []\n",
        "    for f in features:\n",
        "        f = f.cpu()\n",
        "        c = coef if len(f.shape) == 2 else coef.squeeze()\n",
        "        new_f = f[a] * c + f[b] * (1 - c)\n",
        "        new_f = torch.cat([f, new_f], dim=0)\n",
        "        new_features.append(new_f)\n",
        "\n",
        "    if len(new_features) > 0:\n",
        "        return new_pts, new_features\n",
        "    return new_pts\n",
        "\n",
        "\n",
        "if TRI_EXTEND and pts.shape[0] < NUM_PTS:\n",
        "    pts, (pts_col, pts_conf, pts_embed) = extend_pts(pts[:, :3], NUM_PTS, (pts[:, 3:], pts_conf, pts_embed))\n",
        "    pts = torch.cat([pts, pts_col], dim=-1)\n",
        "\n",
        "pts.shape, pts_conf.shape, pts_embed.shape"
      ],
      "metadata": {
        "id": "uGf2RPh832T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if IGNORE_CONF:\n",
        "    print(\"ignore conf\")\n",
        "    pts_conf = pts_conf * 0 + 0.5\n",
        "\n",
        "if IGNORE_EMBED:\n",
        "    print(\"ignore embed\")\n",
        "    pts_embed = torch.randn_like(pts_embed)"
      ],
      "metadata": {
        "id": "FizcFUegSypS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.randperm(pts.shape[0])[:NUM_PTS]\n",
        "\n",
        "pts, pts_col = pts[mask].split([3, 3], dim=-1)\n",
        "pts *= CLOUD_SCALE\n",
        "if pts_col.max() >= 10:\n",
        "    print(\"Convert color\")\n",
        "    pts_col = (pts_col / 255).clamp(min=0, max=1)\n",
        "pts_conf = pts_conf[mask].clamp(min=0, max=1)\n",
        "pts_embed = pts_embed[mask]\n",
        "# pts_embed = torch.cat([pts_col, pts_embed], dim=-1)\n",
        "\n",
        "pts.shape, pts_col.aminmax(), pts_conf.aminmax()"
      ],
      "metadata": {
        "id": "zbgNDq7_sQNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mov = (pts.max() - pts.min()) / pts.shape[0]**0.5\n",
        "# pts += mov * torch.randn_like(pts)\n",
        "# pts.shape, pts_col.shape, pts_conf.shape, pts_embed.shape"
      ],
      "metadata": {
        "id": "ULvBpbYZZVxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersect_box(line_o, line_d, box_d, box_u, fetch_range=False, positive_only=True):\n",
        "    import math\n",
        "    inv_d = 1 / line_d\n",
        "    A = (box_d - line_o) * inv_d\n",
        "    B = (box_u - line_o) * inv_d\n",
        "\n",
        "    def fmx(x):\n",
        "        x = x.clone()\n",
        "        x[x.isnan()] = -math.inf\n",
        "        return x\n",
        "    def fmn(x):\n",
        "        x = x.clone()\n",
        "        x[x.isnan()] = math.inf\n",
        "        return x\n",
        "\n",
        "    def pwmin(A, B):\n",
        "        x = torch.minimum(fmn(A), fmn(B))\n",
        "        x[A.isnan() & B.isnan()] = math.nan\n",
        "        return x\n",
        "    def pwmax(A, B):\n",
        "        x = torch.maximum(fmx(A), fmx(B))\n",
        "        x[A.isnan() & B.isnan()] = math.nan\n",
        "        return x\n",
        "\n",
        "\n",
        "    pmin = pwmin(A, B)\n",
        "    pmax = pwmax(A, B)\n",
        "\n",
        "    vmin = fmx(pmin).max(dim=-1).values\n",
        "    vmax = fmn(pmax).min(dim=-1).values\n",
        "\n",
        "    if positive_only:\n",
        "        vmin = vmin.clamp(min=0)\n",
        "\n",
        "    intersect = vmin + 1e-6 < vmax\n",
        "\n",
        "    if fetch_range:\n",
        "        return intersect, vmin, vmax\n",
        "\n",
        "    return intersect"
      ],
      "metadata": {
        "id": "U-igPhIOd4mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_cloud(pts, pts_col=pts_col, show_norm=False):\n",
        "    import open3d as o3d\n",
        "    cloud = o3d.geometry.PointCloud()\n",
        "    cloud.points = o3d.utility.Vector3dVector(pts.cpu().numpy())\n",
        "    cloud.colors = o3d.utility.Vector3dVector(pts_col.cpu().numpy())\n",
        "    cloud.estimate_normals()\n",
        "    o3d.visualization.draw_geometries([cloud], point_show_normal=show_norm)\n",
        "\n",
        "def estimate_norm(pts, pts_col=pts_col, param=None):\n",
        "    import open3d as o3d\n",
        "    cloud = o3d.geometry.PointCloud()\n",
        "    cloud.points = o3d.utility.Vector3dVector(pts.cpu().numpy())\n",
        "    cloud.colors = o3d.utility.Vector3dVector(pts_col.cpu().numpy())\n",
        "    if param is None:\n",
        "        cloud.estimate_normals()\n",
        "    else:\n",
        "        cloud.estimate_normals(search_param=param)\n",
        "\n",
        "    return torch.from_numpy(np.asarray(cloud.normals))\n"
      ],
      "metadata": {
        "id": "-cVI-iMlHvqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "def plot(pts, conf=None, rgb=None, pov=[DEFAULT_POV], revcol=[False], dpi=64, save=None):\n",
        "    import matplotlib.pyplot as plt\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "    import matplotlib.gridspec as gridspec\n",
        "    import numpy as np\n",
        "\n",
        "    if len(pts.shape) > 2:\n",
        "        pts = pts.squeeze(0)\n",
        "        if conf is not None:\n",
        "            conf = conf.squeeze(0)\n",
        "        if rgb is not None:\n",
        "            rgb = rgb.squeeze(0)\n",
        "    if conf is None:\n",
        "        conf = torch.ones_like(pts[:, 0])\n",
        "    if rgb is None:\n",
        "        rgb = torch.zeros_like(pts)\n",
        "\n",
        "    assert len(pts.shape) == 2\n",
        "\n",
        "    pts = pts.clone().cpu().numpy()\n",
        "    x, y, z = pts[:,0], pts[:,1], pts[:,2]\n",
        "    x -= x.mean()\n",
        "    y -= y.mean()\n",
        "    z -= z.mean()\n",
        "\n",
        "    for rc in revcol:\n",
        "        rgba = torch.cat([rgb if not rc else 1 - rgb, conf.unsqueeze(-1)], dim=-1).cpu().numpy()\n",
        "\n",
        "        def apply_i(pts, i):\n",
        "            x, y, z = pts[...,0], pts[...,1], pts[...,2]\n",
        "            if (i & 4) != 0:    x = -x\n",
        "            if (i & 2) != 0:    y = -y\n",
        "            if (i & 1) != 0:    z = -z\n",
        "            return torch.stack([x, y, z], dim=-1)\n",
        "\n",
        "        for i in pov:\n",
        "            fig = plt.figure(dpi=dpi)\n",
        "            fig.set_size_inches(12, 12, forward=False)\n",
        "            # gs = gridspec.GridSpec(nrows=4, ncols=2, left=0.1, right=2.5, wspace=0.05, hspace=0.1, bottom=0.1, top=4.9)\n",
        "            gs = gridspec.GridSpec(nrows=1, ncols=1, left=0, right=1, wspace=0, hspace=0, bottom=0.0, top=1)\n",
        "\n",
        "            ax = fig.add_subplot(gs[0, 0], projection='3d')\n",
        "            if not rc:\n",
        "                pane_col = (0., 0., 0.5, 0.1)\n",
        "            else:\n",
        "                pane_col = (0., 0., 0., 0.95)\n",
        "            ax.xaxis.set_pane_color(pane_col)\n",
        "            ax.yaxis.set_pane_color(pane_col)\n",
        "            ax.zaxis.set_pane_color(pane_col)\n",
        "\n",
        "            x, y, z = pts[:,0], pts[:,1], pts[:,2]\n",
        "            labx, laby, labz = 'x', 'y', 'z'\n",
        "            if (i & 4) != 0:    x = -x; labx = '-x'\n",
        "            if (i & 2) != 0:    y = -y; laby = '-y'\n",
        "            if (i & 1) != 0:    z = -z; labz = '-z'\n",
        "\n",
        "            ax.scatter(x, y, z, c=rgba, marker='.')\n",
        "\n",
        "            xmid = (x.min() + x.max()) / 2\n",
        "            ymid = (y.min() + y.max()) / 2\n",
        "            zmid = (z.min() + z.max()) / 2\n",
        "            gap = max(x.max() - x.min(), y.max() - y.min(), z.max() - z.min()) / 2\n",
        "\n",
        "            ax.set_xlim(xmid - gap, xmid + gap)\n",
        "            ax.set_ylim(ymid - gap, ymid + gap)\n",
        "            ax.set_zlim(zmid - gap, zmid + gap)\n",
        "\n",
        "            ax.set_xlabel(labx)\n",
        "            ax.set_ylabel(laby)\n",
        "            ax.set_zlabel(labz)\n",
        "\n",
        "            if save is not None:\n",
        "                plt.savefig(save)\n",
        "\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "id": "h6PanX5Zs4pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.randperm(pts.shape[0])[:524288]\n",
        "plot(pts[mask], conf=pts_conf[mask], rgb=pts_col[mask],\n",
        "     save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_cloud.png\")"
      ],
      "metadata": {
        "id": "jq2MRq77tGtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Raw"
      ],
      "metadata": {
        "id": "eeCeRUeR-lLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_W = 800\n",
        "IMG_H = 800"
      ],
      "metadata": {
        "id": "i2dyRZ1YjHpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 128\n",
        "mpl.rcParams['savefig.pad_inches'] = 0\n",
        "\n",
        "def show(img, save=None):\n",
        "    # img = img.astype(np.int)\n",
        "    fig = plt.figure()\n",
        "    # fig.set_size_inches(height * img.shape[0] / img.shape[1], height, forward=False)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "    # img = torch.from_numpy(cv2.resize(img.float().numpy(), [IMG_W, IMG_H]))\n",
        "    if len(img.shape) == 3:\n",
        "        ax.imshow(img)\n",
        "    else:\n",
        "        ax.imshow(img, cmap='gray')\n",
        "    if save is not None:\n",
        "        import imageio\n",
        "        imageio.imwrite(save, img)\n",
        "    plt.show()\n",
        "\n",
        "def enhomo(x):\n",
        "    return torch.cat([x, torch.ones(list(x.shape[:-1]) + [1], device=x.device, dtype=x.dtype)], dim=-1)\n",
        "\n",
        "def dehomo(x):\n",
        "    return x[..., :-1] / x[..., [-1]]\n"
      ],
      "metadata": {
        "id": "A18gjXiPC6Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pfm(filename):\n",
        "    import re\n",
        "    file = open(filename, 'rb')\n",
        "    header = file.readline().decode('utf-8').rstrip()\n",
        "    if header == 'PF':\n",
        "        color = True\n",
        "    elif header == 'Pf':\n",
        "        color = False\n",
        "    else:\n",
        "        raise Exception('Not a PFM file.')\n",
        "\n",
        "    dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', file.readline().decode('utf-8'))\n",
        "    if dim_match:\n",
        "        width, height = map(int, dim_match.groups())\n",
        "    else:\n",
        "        raise Exception('Malformed PFM header.')\n",
        "\n",
        "    scale = float(file.readline().rstrip())\n",
        "    if scale < 0:  # little-endian\n",
        "        endian = '<'\n",
        "        scale = -scale\n",
        "    else:\n",
        "        endian = '>'  # big-endian\n",
        "\n",
        "    data = np.fromfile(file, endian + 'f')\n",
        "    shape = (height, width, 3) if color else (height, width)\n",
        "\n",
        "    data = np.reshape(data, shape)\n",
        "    data = np.flipud(data)\n",
        "    file.close()\n",
        "    return data, scale"
      ],
      "metadata": {
        "id": "C39Qav7JKMAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pix2pts_ns(cam, pix_ind, scale=1, rand=False):\n",
        "    cam_mat_inv = cam[1]\n",
        "    n, m = IMG_W * scale, IMG_H * scale\n",
        "    tmp = torch.stack([pix_ind % m, pix_ind.div(m, rounding_mode='floor')], dim=-1).double()\n",
        "    tmp = (tmp + 0.5).double()\n",
        "    if rand:\n",
        "        mov = (torch.randn_like(tmp) / 16).clamp(min=-1, max=1)\n",
        "        tmp += mov\n",
        "    tmp /= scale\n",
        "    # print(tmp.shape)\n",
        "    tmp = torch.cat([tmp, torch.ones_like(tmp)], dim=-1).double()\n",
        "    # print(tmp.shape)\n",
        "    tmp = dehomo(cam_mat_inv.matmul(tmp.unsqueeze(-1)).squeeze(-1))\n",
        "    tmp = tmp * CLOUD_SCALE\n",
        "    return tmp.float()\n",
        "\n",
        "def pts2pix_ns(cam, pts):\n",
        "    pts = pts / CLOUD_SCALE\n",
        "    cam_mat = cam[0].to(pts.device)\n",
        "    proj = dehomo(cam_mat.matmul(enhomo(pts).double().unsqueeze(-1)).squeeze(-1)).float()\n",
        "    proj = torch.stack([proj[:, 1], proj[:, 0]], dim=-1)\n",
        "    return proj.float()\n",
        "\n",
        "def pix2ray_ns(cam, pix_ind, scale=1, rand=False):\n",
        "    center = cam[2]\n",
        "    pts = pix2pts_ns(cam, pix_ind, scale=scale, rand=rand)\n",
        "    dir = (pts - center)\n",
        "    dir /= dir.norm(dim=-1, keepdim=True).clamp(min=1e-7)\n",
        "    return dir.float()"
      ],
      "metadata": {
        "id": "e8VQqSCKMCSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7srdr5LUxhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data_ns(config, i, for_eval=False, debug=False, ray_upsample=1, full_image=False, return_fn=True):\n",
        "    import cv2\n",
        "    import math\n",
        "\n",
        "    img_file = f\"{DATASET}/{config['frames'][i]['file_path']}.png\"\n",
        "    cam_ext = torch.tensor(config['frames'][i]['transform_matrix'], dtype=torch.double)\n",
        "    cam_ext = cam_ext @ torch.tensor([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]).double()\n",
        "    cam_ext = torch.tensor(scipy.linalg.inv(cam_ext)).double()\n",
        "\n",
        "    focal = 0.5 * IMG_W / math.tan(0.5 * config['camera_angle_x'])\n",
        "    cam_int = torch.tensor([[focal, 0, IMG_W / 2], [0, focal, IMG_H / 2], [0, 0, 1]], dtype=torch.double)\n",
        "\n",
        "    raw_img = cv2.imread(img_file, cv2.IMREAD_UNCHANGED)\n",
        "    opa = torch.from_numpy(raw_img[:, :, -1] / 255)\n",
        "    img = torch.from_numpy(raw_img[:, :, :3][:, :, ::-1] / 255)\n",
        "\n",
        "    # img2 = torch.from_numpy(cv2.imread(img_file)[:, :, ::-1] / 255)\n",
        "    # show(img2)\n",
        "    # show(img)\n",
        "    # print((img2 - img).abs().max())\n",
        "    # return\n",
        "\n",
        "    opa_thres = opa[opa > 0].min() - 1e-6\n",
        "    if debug:\n",
        "        print(\"opa_thres\", opa_thres)\n",
        "\n",
        "    cam_mat = cam_int.double().mm(cam_ext.double()[:-1])\n",
        "    cam_center = dehomo(torch.tensor(scipy.linalg.null_space(cam_mat.double())).squeeze()).float() * CLOUD_SCALE\n",
        "    cam_mat_inv = torch.tensor(scipy.linalg.inv(torch.cat([cam_mat, torch.tensor([[0., 0., 0., 1.]])], dim=0).double()))\n",
        "    cam = (cam_mat, cam_mat_inv, cam_center)\n",
        "\n",
        "    orig_img = img\n",
        "    orig_opa = opa\n",
        "\n",
        "    if ray_upsample != 1:\n",
        "        qsize = (img.shape[1] * ray_upsample, img.shape[0] * ray_upsample)\n",
        "        # print(type(qsize))\n",
        "        resize = lambda x : torch.from_numpy(cv2.resize(x.numpy(), qsize))\n",
        "\n",
        "\n",
        "        OPA_FIX_MUL = 1024\n",
        "        OPA_FIX_MOV = OPA_FIX_MUL - 1\n",
        "        opa[opa < opa_thres] = -OPA_FIX_MOV\n",
        "        opa = (opa + OPA_FIX_MOV) / OPA_FIX_MUL\n",
        "        opa = resize(opa)\n",
        "        opa = opa * OPA_FIX_MUL - OPA_FIX_MOV\n",
        "\n",
        "        if debug:\n",
        "            print(\"opa\", opa[opa>0].min().item(), opa.max().item())\n",
        "            print(((opa < opa_thres) * (opa > -OPA_FIX_MOV)).sum())\n",
        "            show((opa < opa_thres) * (opa > -OPA_FIX_MOV))\n",
        "\n",
        "            # return opa, None\n",
        "\n",
        "        opa[opa < opa_thres] = 0\n",
        "\n",
        "        img = torch.from_numpy(raw_img[:, :, :3][:, :, ::-1] / 255)\n",
        "        img = resize(img)\n",
        "\n",
        "    if for_eval:\n",
        "        img = img * opa.unsqueeze(-1) + torch.tensor(BG_COLOR)\n",
        "        orig_img = orig_img * orig_opa.unsqueeze(-1) + torch.tensor(BG_COLOR)\n",
        "\n",
        "        # print(img.shape)\n",
        "\n",
        "    if full_image:\n",
        "        opa_thres = -math.inf\n",
        "\n",
        "    dep = (opa >= opa_thres)\n",
        "    orig_dep = (orig_opa >= opa_thres)\n",
        "    assert orig_dep.shape == orig_img.shape[:2]\n",
        "    assert dep.shape == img.shape[:2]\n",
        "    # print(dep.shape, orig_dep.shape)\n",
        "\n",
        "    if for_eval and BORDER_FIX_KER > 0:\n",
        "        K = BORDER_FIX_KER\n",
        "        H, W = dep.shape\n",
        "        deps = []\n",
        "        imgs = []\n",
        "\n",
        "        resize = lambda x : torch.from_numpy(cv2.resize(x.numpy(), dep.shape[::-1]))\n",
        "        tmp_img = resize(img)\n",
        "        tmp_img[~dep] *= 0\n",
        "        tmp_img[~dep] += torch.tensor(BG_COLOR).float()\n",
        "        for a in range(K+1):\n",
        "            for b in range(K+1):\n",
        "                deps.append(dep[a:, b:][:H-K, :W-K])\n",
        "                imgs.append(tmp_img[a:, b:][:H-K, :W-K])\n",
        "\n",
        "        deps = torch.stack(deps, dim=-1).float().std(dim=-1)\n",
        "        imgs = torch.stack(imgs, dim=-1).float().std(dim=-1).max(dim=-1).values\n",
        "        bad_border = (deps > deps.mean() + 2 * deps.std()) & (imgs > imgs.mean() + BORDER_FIX_THRES * imgs.std())\n",
        "\n",
        "        if debug:\n",
        "            show(tmp_img)\n",
        "            show(bad_border)\n",
        "\n",
        "        HB, WB = bad_border.shape\n",
        "        for a in range(K+1):\n",
        "            for b in range(K+1):\n",
        "                dep[a:, b:][:HB, :WB] &= ~bad_border\n",
        "\n",
        "    def img_outlier(pts):\n",
        "        W, H = orig_dep.shape\n",
        "        pix = pts2pix_ns(cam, pts)\n",
        "        pix = pix.long()\n",
        "        ind = torch.arange(pts.shape[0], device='cuda')\n",
        "\n",
        "        mask = (pix[:, 0] >= 0) & (pix[:, 1] >= 0) & (pix[:, 0] < H) & (pix[:, 1] < W)\n",
        "        pix = pix[mask]\n",
        "        ind = ind[mask]\n",
        "\n",
        "        pix_ind = pix[:, 0] * W + pix[:, 1]\n",
        "        inlier = orig_dep.cuda().reshape(-1)[pix_ind]\n",
        "        ind = ind[inlier]\n",
        "\n",
        "        if debug:\n",
        "            outlier = ~inlier\n",
        "            tmp_img = orig_dep * 0\n",
        "            tmp_img.view(-1)[pix_ind[outlier]] = 1\n",
        "            print(\"outliers:\", outlier.sum())\n",
        "            show(tmp_img)\n",
        "\n",
        "        return ind\n",
        "\n",
        "    img_outlier_fn = lambda pts: img_outlier(pts)\n",
        "\n",
        "\n",
        "    ## DEBUG\n",
        "    if debug:\n",
        "        pass\n",
        "        proj = pts2pix_ns(cam, pts)\n",
        "        mask = (proj[:, 0] >= 0) & (proj[:, 1] >= 0) & (proj[:, 0] <= IMG_H) & (proj[:, 1] <= IMG_W)\n",
        "        proj = proj[mask]\n",
        "        pimg = torch.sparse_coo_tensor(indices=proj.long().T, values=pts_col[mask].mean(dim=-1), size=[IMG_W, IMG_H]).to_dense()\n",
        "        pimg = pimg != 0\n",
        "        show(pimg)\n",
        "\n",
        "        pixels = torch.arange(IMG_W * IMG_H)\n",
        "        restored = pts2pix_ns(cam, pix2pts_ns(cam, pixels)).long()\n",
        "        restored = restored[:, 0] * IMG_W + restored[:, 1]\n",
        "        print(pixels[:10], restored[:10])\n",
        "        assert not (pixels != restored).any()\n",
        "\n",
        "\n",
        "        print(pimg.shape, img.shape)\n",
        "        # show(img)\n",
        "        # show(dep)\n",
        "        # show(img * dep[:,:,None])\n",
        "        # show(img * (~dep[:,:,None]))\n",
        "        print(\"opa:\", opa.aminmax())\n",
        "        show(opa)\n",
        "        show(~dep)\n",
        "        # show(img * opa.unsqueeze(-1))\n",
        "        # show(img * pimg[:,:,None])\n",
        "        # show(img * dep[:,:,None] * pimg[:,:,None])\n",
        "\n",
        "        # print(orig_img.shape)\n",
        "        # show(orig_img)\n",
        "        # show(orig_dep)\n",
        "        # show(orig_img * orig_dep[:,:,None])\n",
        "        # show(orig_img * (~orig_dep[:,:,None]))\n",
        "\n",
        "    if not for_eval:\n",
        "        img[dep <= 0] -= 4\n",
        "        orig_img[orig_dep <= 0] -= 4\n",
        "\n",
        "        for d, k in zip([dep, orig_dep], [ray_upsample, 1]):\n",
        "            tmp = d.clone()\n",
        "            for k in range(1, 1 + IMAGE_TRAIN_BG_PAD*k):\n",
        "                # BORDER PADDING\n",
        "                d[k:, :] |= tmp[:-k, :]\n",
        "                d[:-k, :] |= tmp[k:, :]\n",
        "                d[:, k:] |= tmp[:, :-k]\n",
        "                d[:, :-k] |= tmp[:, k:]\n",
        "\n",
        "            if debug:\n",
        "                show(tmp != d)\n",
        "\n",
        "\n",
        "        if debug:\n",
        "            print(\"border padding\")\n",
        "            show(img)\n",
        "            show(orig_img)\n",
        "\n",
        "\n",
        "\n",
        "    if for_eval or (not return_fn):\n",
        "        # print(\"1\")\n",
        "        ans = img[dep].float()\n",
        "        pix_used = torch.arange(img.shape[0] * img.shape[1]).reshape(img.shape[:2])[dep]\n",
        "        line_o = cam_center.unsqueeze(0).expand(pix_used.shape[0], -1)\n",
        "        line_d_fn = lambda : pix2ray_ns(cam, pix_used, scale=ray_upsample, rand=TRAIN_RANDOM_AUG and not for_eval)\n",
        "        line_d = line_d_fn()\n",
        "        data_fn = lambda : line_d_fn(), ans\n",
        "    else:\n",
        "        # print(\"2\")\n",
        "        ans_all = img\n",
        "        opa_all = opa\n",
        "        pix_all = torch.arange(img.shape[0] * img.shape[1])\n",
        "\n",
        "        patch_dep = orig_dep\n",
        "        patch_img = orig_img\n",
        "        patch_size = IMAGE_PATCH_TRAIN * ray_upsample\n",
        "\n",
        "        if IMAGE_PATCH_TRAIN > 1:\n",
        "            a, b = orig_img.shape[:2][::-1]\n",
        "            tmp = (a // IMAGE_PATCH_TRAIN, b // IMAGE_PATCH_TRAIN)\n",
        "            resize = lambda x : torch.from_numpy(cv2.resize(x.numpy(), tmp, interpolation=cv2.INTER_NEAREST))\n",
        "            patch_dep = resize(orig_dep.float()) > mask_thres\n",
        "\n",
        "            if debug:\n",
        "                print(\"patched\")\n",
        "                patch_img = resize(img)\n",
        "                # show(patch_dep)\n",
        "                # show(patch_img)\n",
        "                # show(patch_dep[:,:,None]*patch_img)\n",
        "                # show(~patch_dep[:,:,None]*patch_img)\n",
        "\n",
        "        h, w = patch_dep.shape\n",
        "        pix_all = pix_all.reshape(h, patch_size, w, patch_size)\n",
        "        ans_all = ans_all.reshape(h, patch_size, w, patch_size, 3)\n",
        "        opa_all = opa_all.reshape(h, patch_size, w, patch_size, 1)\n",
        "        pix_all = pix_all.permute(0, 2, 1, 3).reshape(h, w, patch_size**2)[patch_dep]\n",
        "        ans_all = ans_all.permute(0, 2, 1, 3, 4).reshape(h, w, patch_size**2, 3)[patch_dep]\n",
        "        opa_all = opa_all.permute(0, 2, 1, 3, 4).reshape(h, w, patch_size**2, 1)[patch_dep]\n",
        "        ans_all = torch.cat([ans_all, opa_all], dim=-1)\n",
        "        line_o = cam_center.unsqueeze(0).expand(ans_all.shape[0], -1)\n",
        "\n",
        "        if debug:\n",
        "            print(\"check\")\n",
        "            cho = torch.randint(low=0, high=patch_size**2, size=[pix_all.shape[0], 1])\n",
        "            pix = pix_all.gather(1, cho).squeeze(1)\n",
        "            ans = ans_all.gather(1, cho.unsqueeze(-1).expand(-1, -1, 4)).squeeze(1)\n",
        "            tmp = patch_img.clone()\n",
        "            tmp[patch_dep] = ans[:, :3]\n",
        "            show(tmp)\n",
        "\n",
        "        # print(img.shape, ans_all.shape, ans_all.std(dim=1).sum())\n",
        "\n",
        "        def generate_data():\n",
        "            cho = torch.randint(low=0, high=patch_size**2, size=[pix_all.shape[0], 1])\n",
        "            pix = pix_all.gather(1, cho).squeeze(1)\n",
        "            ans = ans_all.gather(1, cho.unsqueeze(-1).expand(-1, -1, 4)).squeeze(1)\n",
        "            line_d = pix2ray_ns(cam, pix, scale=ray_upsample, rand=TRAIN_RANDOM_AUG)\n",
        "            return line_d, ans\n",
        "\n",
        "        data_fn = lambda : generate_data()\n",
        "\n",
        "    if debug:\n",
        "        line_d, ans = data_fn()\n",
        "        print(\"data_fn called\", line_o.shape, line_d.shape, ans.shape)\n",
        "\n",
        "    # print(line_o.shape, line_d.shape, ans.shape)\n",
        "\n",
        "    ## DEBUG\n",
        "    # if debug:\n",
        "    #     mask = torch.randint(low=0, high=ans.shape[0], size=[50])\n",
        "    #     plot(pts, conf=pts_conf, rgb=pts_col, pov=[1], cam_center=cam_center, rays=(line_o[mask], line_d[mask]))\n",
        "\n",
        "    if for_eval:\n",
        "        return line_o, line_d, ans, (dep, orig_dep, img.float(), orig_img.float())\n",
        "    if return_fn:\n",
        "        return line_o, data_fn, img_outlier_fn\n",
        "    return line_o, line_d, ans"
      ],
      "metadata": {
        "id": "8zOLCKN7_SHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_o, data_fn, img_outlier_fn = read_data_ns(valid_config, 0, debug=True, full_image=False, ray_upsample=IMAGE_SCALE_TRAIN)\n",
        "img_outlier_fn(pts.cuda())\n",
        "img_outlier_fn(((pts - pts.mean(dim=0)) * 1.05 + pts.mean(dim=0)).cuda())"
      ],
      "metadata": {
        "id": "d-f7rLn8niMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RayDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, o, d=None, ans=None, fn=None):\n",
        "        super().__init__()\n",
        "        self.o = o\n",
        "        self.d = d\n",
        "        self.ans = ans\n",
        "        self.fn = fn\n",
        "\n",
        "    def generate_fn(self):\n",
        "        if self.fn is not None:\n",
        "            data = [f() for f in self.fn]\n",
        "            self.d = torch.cat([d[0] for d in data], dim=0)\n",
        "            self.ans = torch.cat([d[1] for d in data], dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.o.shape[0]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.o[i], self.d[i], self.ans[i]\n",
        "\n",
        "    def loader(self, **kwargs):\n",
        "        self.generate_fn()\n",
        "        return torch.utils.data.DataLoader(self, **kwargs)\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, imgs):\n",
        "        super().__init__()\n",
        "        self.imgs = imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.imgs[i]"
      ],
      "metadata": {
        "id": "T-egSExe0xea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_config is not None and not eval_only:\n",
        "    train_o = []\n",
        "    train_fn = []\n",
        "    prune_outlier_fn = []\n",
        "\n",
        "    for i in tqdm(range(len(train_config['frames']))):\n",
        "        import gc\n",
        "        gc.collect()\n",
        "        o, fn, ofn = read_data_ns(train_config, i, ray_upsample=IMAGE_SCALE_TRAIN, return_fn=True)\n",
        "        train_o.append(o)\n",
        "        train_fn.append(fn)\n",
        "        prune_outlier_fn.append(ofn)\n",
        "\n",
        "    grow_o = train_o\n",
        "    grow_fn = train_fn\n",
        "\n",
        "    train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "    train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "    train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "    print(len(train_dataset))"
      ],
      "metadata": {
        "id": "N4SeUBbI-nUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_config is not None and not eval_only:\n",
        "    if grow_extra_config is not None:\n",
        "        for i in tqdm(range(len(grow_extra_config['frames']))):\n",
        "            o, fn = read_data_ns(grow_extra_config, i, ray_upsample=IMAGE_SCALE_TRAIN, return_fn=True)\n",
        "            grow_o.append(o)\n",
        "            grow_fn.append(fn)\n",
        "\n",
        "    grow_o = torch.cat(grow_o * TRAIN_REPEAT, dim=0)\n",
        "    grow_fn = grow_fn * TRAIN_REPEAT\n",
        "\n",
        "    grow_dataset = RayDataset(grow_o, fn=grow_fn)\n",
        "    print(len(grow_dataset))"
      ],
      "metadata": {
        "id": "El3edZJRZSaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_config is not None and not eval_only:\n",
        "    if prune_extra_config is not None:\n",
        "        for i in tqdm(range(len(prune_extra_config['frames']))):\n",
        "            o, fn, ofn = read_data_ns(prune_extra_config, i, ray_upsample=1, return_fn=True)\n",
        "            prune_outlier_fn.append(ofn)\n",
        "\n",
        "    len(prune_outlier_fn)"
      ],
      "metadata": {
        "id": "OASsxfrKFlsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_imgs = []\n",
        "\n",
        "for i in tqdm(range(len(valid_config['frames']))):\n",
        "    o, d, a, eval_info = read_data_ns(valid_config, i, for_eval=True, ray_upsample=IMAGE_SCALE)\n",
        "    rayset = RayDataset(o, d, a)\n",
        "    valid_imgs.append([rayset, eval_info])\n",
        "\n",
        "valid_dataset = ImageDataset(valid_imgs)\n",
        "print(len(valid_dataset))"
      ],
      "metadata": {
        "id": "3OhAAmDq2sMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "B8BHPQoLdapb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_config is not None and not eval_only:\n",
        "    # preprocess cloud to remove image outliers\n",
        "    ind = torch.arange(pts.shape[0], device='cuda')\n",
        "    pts = pts.cuda()\n",
        "\n",
        "    for ofn in tqdm(prune_outlier_fn):\n",
        "        mask = ofn(pts)\n",
        "        ind = ind[mask]\n",
        "        pts = pts[mask]\n",
        "\n",
        "    logging.info(f\"maintain: remove {pts_embed.shape[0] - ind.shape[0]} image outliers\")\n",
        "    pts = pts.cpu()\n",
        "    ind = ind.cpu()\n",
        "    pts_embed = pts_embed[ind]\n",
        "    pts_conf = pts_conf[ind]\n",
        "    pts_col = pts_col[ind]"
      ],
      "metadata": {
        "id": "BJNfMnCgtHlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Field"
      ],
      "metadata": {
        "id": "2l9QquTj2FwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from field.kd_field import KDField\n",
        "from field.multi_field import MultiField"
      ],
      "metadata": {
        "id": "X5-yT-TenSPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LAYER = 22 if CLOUD_NAME == \"cloud_gt\" else 21"
      ],
      "metadata": {
        "id": "jbXdY-w62gho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_field(pts, pts_embed, pts_conf):\n",
        "    return KDField(embed_dim=32, #32,\n",
        "\n",
        "                   resume_immediately=eval_only,\n",
        "\n",
        "                   max_pts_lim=2**21,\n",
        "                   bnd_pad_fact=1, #2**0.5, # 1\n",
        "                   spline_samples=8, num_support=96, num_support_nn=32,\n",
        "\n",
        "                #    bnd_pad_ignore_bnd=True,\n",
        "\n",
        "                   mesh_reg_weight=200,\n",
        "                   warmup_mult=0.5,\n",
        "                #    mesh_reg_weight=0,\n",
        "                #    warmup_mult=1e-6,\n",
        "\n",
        "                   # refnerf mode:\n",
        "                   refnerf_mode=True,\n",
        "                   manual_grad=False,\n",
        "                   mlp_shapes=[16, 48, 128],\n",
        "\n",
        "                   # classic mode:\n",
        "                #    refnerf_mode=False,\n",
        "                #    sh_deg=3,\n",
        "                #    mlp_shapes=[32, 48, 72],\n",
        "\n",
        "                   norm_mesh_param=NORM_MESH_PARAM,\n",
        "                   reg_samples=1,\n",
        "                   use_open3d_unit_len=True,\n",
        "                   disable_conf_recenter=True,\n",
        "                   adjust_height=True,\n",
        "                   adaptive_support=True,\n",
        "                   norm_mesh_remove_outlier=False,\n",
        "                #    use_roughness=False,\n",
        "                #    dropout=1/8, pts_dropout=0,\n",
        "                   num_layer=MAX_LAYER, num_trees=1, pts=pts,\n",
        "                   int_height_min=1, int_height_max=4, sample_height_max=5,\n",
        "                   pts_embed=pts_embed, pts_conf=pts_conf, default_field_val=BG_COLOR,\n",
        "                   train_single_tree=True).cuda()"
      ],
      "metadata": {
        "id": "uRLan9CyuDFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field = create_field(pts, pts_embed, pts_conf)"
      ],
      "metadata": {
        "id": "_beGZw93ngsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field"
      ],
      "metadata": {
        "id": "TmHoabuL9_Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in field.state_dict().items():\n",
        "    print(name, param.shape)"
      ],
      "metadata": {
        "id": "ru4nr9bepbTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "qdRZFuB-3on2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img2mse = lambda x, y : torch.mean((x - y) ** 2)\n",
        "mse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.]).to(x.device))"
      ],
      "metadata": {
        "id": "oLoU1s8e6sfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Stat:\n",
        "    def __init__(self):\n",
        "        self.clear()\n",
        "\n",
        "    def clear(self):\n",
        "        self.correct = 0\n",
        "        self.total = 0\n",
        "\n",
        "    def add(self, cor, num=1, mean=True):\n",
        "        if isinstance(cor, torch.Tensor):\n",
        "            cor = cor.item()\n",
        "        if isinstance(num, torch.Tensor):\n",
        "            num = num.item()\n",
        "        if mean:\n",
        "            cor *= num\n",
        "        self.correct += cor\n",
        "        self.total += num\n",
        "\n",
        "    def result(self, clear=True):\n",
        "        ret = self.correct / max(self.total, 1e-5)\n",
        "        if clear:\n",
        "            self.clear()\n",
        "        return ret\n",
        "\n",
        "    def preview(self):\n",
        "        return self.result(clear=False)\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"%.6lf\" % self.result()"
      ],
      "metadata": {
        "id": "dVz-mg736A3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Prefix:\n",
        "    def __init__(self, a, n=None, ratio=None):\n",
        "        self.a = a\n",
        "\n",
        "        if ratio is not None:\n",
        "            assert n is None\n",
        "            n = int(len(a) * ratio + 0.5)\n",
        "        else:\n",
        "            assert n is not None\n",
        "\n",
        "        self.n = min(n, len(a))\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.i = 0\n",
        "        self.k = iter(self.a)\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.i >= self.n:\n",
        "            raise StopIteration\n",
        "        self.i += 1\n",
        "        return next(self.k)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n"
      ],
      "metadata": {
        "id": "jg6ulSBYK5eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contour_rgb(pts):\n",
        "    r = torch.tensor([1, 0, 0]).float().cuda()\n",
        "    g = torch.tensor([0, 1, 0]).float().cuda()\n",
        "    b = torch.tensor([0, 0, 1]).float().cuda()\n",
        "    z = pts[:, 2].clone()\n",
        "    min, max = z.aminmax()\n",
        "    z = (z - min) / (max - min)\n",
        "    z = z.unsqueeze(-1)\n",
        "    c0 = (z - 0/2) * g + (1/2 - z) * b\n",
        "    c1 = (z - 1/2) * r + (2/2 - z) * g\n",
        "    c0 *= 2\n",
        "    c1 *= 2\n",
        "    rgb = torch.where(z.expand(-1, 3) < 0.5, c0, c1)\n",
        "    return rgb"
      ],
      "metadata": {
        "id": "f5BU3VXsWo3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import sys\n",
        "import lpips\n",
        "\n",
        "lpips_alex = lpips.LPIPS(net='alex').cuda()\n",
        "lpips_vgg = lpips.LPIPS(net='vgg').cuda()\n",
        "\n",
        "def compute_metrics(x, y):\n",
        "    with torch.no_grad():\n",
        "        xx = x.permute(2, 0, 1).unsqueeze(0).cuda()\n",
        "        yy = y.permute(2, 0, 1).unsqueeze(0).cuda()\n",
        "\n",
        "        metrics = {\n",
        "            'psnr': psnr(x.cpu().numpy(), y.cpu().numpy()),\n",
        "            'ssim': ssim(x.cpu().numpy(), y.cpu().numpy(), win_size=11, multichannel=True),\n",
        "            'lpips_alex': lpips_alex(xx, yy).item(),\n",
        "            'lpips_vgg': lpips_vgg(xx, yy).item(),\n",
        "            # 'fid': state.metrics[\"fid\"],\n",
        "        }\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "RlUVcLw3ANR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(field, valid_dataset, show_sample=False, show_all=False, show_predict_only=False,\n",
        "             batch_size=4096, inpaint=False, norm_map=False, export_file=None):\n",
        "    import gc\n",
        "\n",
        "    gc.collect()\n",
        "    field.deploy()\n",
        "    stat_psnr = Stat()\n",
        "    stat_ssim = Stat()\n",
        "    stat_lpips_alex = Stat()\n",
        "    stat_lpips_vgg = Stat()\n",
        "\n",
        "    if show_sample is not False:\n",
        "        if show_sample is True:\n",
        "            show_sample = random.randint(0, len(valid_dataset) - 1)\n",
        "    else:\n",
        "        show_sample = None\n",
        "\n",
        "    if norm_map:\n",
        "        logging.debug(f\"Norm Map:\")\n",
        "\n",
        "        pts = field.pts.cpu()\n",
        "        norms = []\n",
        "        with torch.no_grad():\n",
        "            pts_embed = field.pts_embed()\n",
        "            for i in tqdm(range(0, pts_embed.shape[0], 65536)):\n",
        "                batch = pts_embed[i : i + 65536]\n",
        "                norm = field.feed_pts_norm(field.feed_fea(batch))\n",
        "                if field.enable_space_transform:\n",
        "                    st = field.pts_space_transform[i : i + 65536]\n",
        "                    st = st.reshape(-1, 3, 3)\n",
        "                    norm = norm.unsqueeze(-2).matmul(st.transpose(-1, -2)).squeeze(-2)\n",
        "\n",
        "                from field.kd_field import fix_norm_direction\n",
        "                norm = fix_norm_direction(norm, -torch.tensor(DEFAULT_VIEW_DIR).float().cuda())\n",
        "                norms.append(norm)\n",
        "        norms = torch.cat(norms, dim=0).cpu()\n",
        "        mask = torch.randperm(pts.shape[0])[:524288]\n",
        "        plot(pts[mask], rgb=norms[mask]*0.5+0.5, dpi=64,\n",
        "             save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_norm_pred.png\")\n",
        "\n",
        "    if export_file is not None:\n",
        "        ckpt = []\n",
        "\n",
        "    tbar = tqdm(valid_dataset, mininterval=5)\n",
        "    tbar.set_description(\"Eval\")\n",
        "    for i, (img, eval_info) in enumerate(tbar):\n",
        "        with logging_redirect_tqdm():\n",
        "            predict = []\n",
        "            loader = img.loader(batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=7)\n",
        "            for j, (line_o, line_d, _) in enumerate(loader):\n",
        "                if j % 100 == 0:\n",
        "                    tbar.set_postfix_str(f\"batch: {j+1}/{len(loader)}, psnr: {stat_psnr.preview():.4f}\")\n",
        "                line_o = line_o.cuda()\n",
        "                line_d = line_d.cuda()\n",
        "                with torch.no_grad():\n",
        "                    pred, _, _ = field(line_o, line_d, sample_per_box=0)\n",
        "                    pred[~field.line_intersect] -= 100000\n",
        "                    predict.append(pred.cpu())\n",
        "\n",
        "            scaled_mask, orig_mask, scaled_img, orig_img = eval_info\n",
        "            predict = torch.cat(predict, dim=0)\n",
        "\n",
        "            scaled_img[scaled_mask] = predict\n",
        "            predict = scaled_img\n",
        "\n",
        "            if inpaint and (predict < 0).any():\n",
        "                zero_mask = (predict.min(dim=-1).values < 0).to(torch.uint8)\n",
        "                predict = torch.from_numpy(cv2.inpaint((predict * 255).to(torch.uint8).numpy(),\n",
        "                                                    zero_mask.numpy(), 3 * IMAGE_SCALE, cv.INPAINT_TELEA)) / 255\n",
        "                if zero_mask.sum().item() > 100:\n",
        "                    logging.debug(f\"Inpainted {zero_mask.sum().item()} pixels\")\n",
        "\n",
        "            if IMAGE_SCALE != 1:\n",
        "                qsize = (orig_img.shape[1], orig_img.shape[0])\n",
        "                resize = lambda x : torch.from_numpy(cv2.resize(x.numpy(), qsize,\n",
        "                                                                interpolation=cv2.INTER_NEAREST))\n",
        "                predict = resize(predict)\n",
        "\n",
        "            predict[~orig_mask] = orig_img[~orig_mask]\n",
        "            target = orig_img\n",
        "\n",
        "            predict = predict.clamp(min=0, max=1)\n",
        "            # make sure both are 8bit\n",
        "            # predict = (predict * 255).round() / 255\n",
        "            # target = (target * 255).round() / 255\n",
        "\n",
        "            if export_file is not None:\n",
        "                ckpt.append([predict.cpu(), target.cpu()])\n",
        "\n",
        "            if show_all:\n",
        "                a, b = predict, target\n",
        "                logging.debug(f\"Image #{i}\")\n",
        "                logging.debug(f\"Predict:\")\n",
        "                show(a.numpy(),\n",
        "                    save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_valid{i}_pred.png\")\n",
        "\n",
        "                if not show_predict_only:\n",
        "                    logging.debug(f\"Target:\")\n",
        "                    show(b.numpy(),\n",
        "                        save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_valid{i}_target.png\")\n",
        "                    logging.debug(f\"Diff:\")\n",
        "                    show((a - b).abs().mean(dim=-1).clamp(min=0, max=1).numpy(),\n",
        "                        save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_valid{i}_diff.png\")\n",
        "\n",
        "            elif i == show_sample:\n",
        "                sample = (predict, target)\n",
        "\n",
        "            # Eval with orig_mask\n",
        "            if EVAL_MASK_ONLY:\n",
        "                predict = preidct[orig_mask]\n",
        "                target = target[orig_mask]\n",
        "\n",
        "            # stat_psnr.add(mse2psnr(img2mse(predict, target)))\n",
        "            metrics = compute_metrics(predict, target)\n",
        "            stat_psnr.add(metrics['psnr'])\n",
        "            stat_ssim.add(metrics['ssim'])\n",
        "            stat_lpips_alex.add(metrics['lpips_alex'])\n",
        "            stat_lpips_vgg.add(metrics['lpips_vgg'])\n",
        "\n",
        "            if show_all:\n",
        "                logging.debug(f\"PSNR: {mse2psnr(img2mse(predict, target)).item():.6f}\")\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                logging.info(f\"Eval {i}/{len(tbar)}: psnr: {stat_psnr.preview():.4f}\")\n",
        "\n",
        "    field.undeploy()\n",
        "\n",
        "    if export_file is not None:\n",
        "        logging.info(f\"Save to {export_file}\")\n",
        "        torch.save(ckpt, export_file)\n",
        "\n",
        "    if (not show_all) and show_sample is not None:\n",
        "        a, b = sample\n",
        "        logging.debug(f\"Sample image #{show_sample}\")\n",
        "        logging.debug(f\"Predict:\")\n",
        "        show(a.numpy(),\n",
        "             save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_valid{show_sample}_pred.png\")\n",
        "        if not show_predict_only:\n",
        "            logging.debug(f\"Target:\")\n",
        "            show(b.numpy(),\n",
        "                save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_valid{show_sample}_target.png\")\n",
        "            logging.debug(f\"Diff:\")\n",
        "            show((a - b).abs().mean(dim=-1).clamp(min=0, max=1).numpy(),\n",
        "                save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_valid{show_sample}_diff.png\")\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    logging.info(f\"psnr: {stat_psnr.preview()}\")\n",
        "    logging.info(f\"ssim: {stat_ssim.preview()}\")\n",
        "    logging.info(f\"lpips_alex: {stat_lpips_alex.preview()}\")\n",
        "    logging.info(f\"lpips_vgg: {stat_lpips_vgg.preview()}\")\n",
        "\n",
        "    return stat_psnr"
      ],
      "metadata": {
        "id": "sk1HqxVeA66n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(field, exp_name=\"field\", OUTPUT=\"./scratch/\", lr=5e-3, min_lr=1e-6, valid_epoch=1, eloss_coef=0,\n",
        "          num_epoch=1000000, start_epoch=0, batch_size=4096, grow_batch_size=8192, eval_batch_size=4096, resume_ckpt=None,\n",
        "          sch_T=10, grow_sch_T_fact=1, grow_epoch_fact=1, rebuild_tree_fact=2, conf_reg_coef=0.0003,\n",
        "          sch_start_0=False, first_grow_epoch=10, last_grow_epoch=100):\n",
        "    import math\n",
        "    import gc\n",
        "    logging.info(f\"Train {exp_name} OUTPUT = {OUTPUT}\")\n",
        "\n",
        "\n",
        "\n",
        "    col_encode_rep = 0\n",
        "\n",
        "    print_epoch = 1\n",
        "    show_epoch = valid_epoch\n",
        "\n",
        "    save_epoch = 1\n",
        "\n",
        "    rebuild_tree_epoch = rebuild_tree_fact * sch_T\n",
        "    grow_sch_T = int(grow_sch_T_fact * sch_T + 0.5)\n",
        "    grow_epoch = int(grow_epoch_fact * grow_sch_T + 0.5)\n",
        "\n",
        "    sample_per_box = 4\n",
        "    do_grow = False\n",
        "\n",
        "    best_eval_res = -1\n",
        "\n",
        "    def get_opt_sch(field, T):\n",
        "        logging.info(f\"init opt_sch T = {T}\")\n",
        "        opt = torch.optim.Adam(field.parameters(), lr=lr)\n",
        "        # sch = torch.optim.lr_scheduler.ExponentialLR(opt, 0.5)\n",
        "        # sch_step_epoch = 10\n",
        "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=T, eta_min=min_lr)\n",
        "        return opt, sch\n",
        "    T = grow_sch_T if (first_grow_epoch <= start_epoch < last_grow_epoch) else sch_T\n",
        "    opt, sch = get_opt_sch(field, T)\n",
        "    sch_step_epoch = 1\n",
        "    if sch_start_0:\n",
        "        opt.zero_grad()\n",
        "        opt.step()\n",
        "        for i in range(sch_T):\n",
        "            sch.step()\n",
        "        logging.info(f\"start_0 lr = {sch.get_last_lr()[0]}\")\n",
        "\n",
        "    if resume_ckpt:\n",
        "        resume_ckpt, ckpt = resume_ckpt\n",
        "        logging.info(f\"ckpt loaded from {resume_ckpt}\")\n",
        "        opt.load_state_dict(ckpt['opt'])\n",
        "        sch.load_state_dict(ckpt['sch'])\n",
        "        best_eval_res = ckpt['best_eval_res']\n",
        "        del ckpt\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    def hyperparam(name, var_map=locals() | globals()):\n",
        "        val = var_map[name]\n",
        "        logging.info(f\"Hyperparam {name} = {val}\")\n",
        "\n",
        "    if True:\n",
        "        logging.info(\"Dataset hyperparams:\")\n",
        "        hyperparam(\"SCENE\")\n",
        "        hyperparam(\"DATASET\")\n",
        "        hyperparam(\"CLOUD_NAME\")\n",
        "        hyperparam(\"LIGHT_IND\")\n",
        "        hyperparam(\"CLOUD_SCALE\")\n",
        "        hyperparam(\"IMAGE_SCALE\")\n",
        "        hyperparam(\"IMAGE_SCALE_TRAIN\")\n",
        "        hyperparam(\"IMAGE_PATCH_TRAIN\")\n",
        "        hyperparam(\"TRAIN_RANDOM_AUG\")\n",
        "        hyperparam(\"TRAIN_REPEAT\")\n",
        "        hyperparam(\"NUM_PTS\")\n",
        "        hyperparam(\"IGNORE_CONF\")\n",
        "        hyperparam(\"IGNORE_EMBED\")\n",
        "        hyperparam(\"BORDER_FIX_KER\")\n",
        "        hyperparam(\"BORDER_FIX_THRES\")\n",
        "        hyperparam(\"EVAL_MASK_ONLY\")\n",
        "        hyperparam(\"BG_COLOR\")\n",
        "        hyperparam(\"IMAGE_TRAIN_BG_PAD\")\n",
        "\n",
        "        logging.info(\"Model hyperparams:\")\n",
        "        hyperparam(\"MAX_LAYER\")\n",
        "        hyperparam(\"lr\")\n",
        "        hyperparam(\"sch_T\")\n",
        "        hyperparam(\"grow_sch_T\")\n",
        "        hyperparam(\"start_epoch\")\n",
        "        hyperparam(\"batch_size\")\n",
        "        hyperparam(\"grow_batch_size\")\n",
        "        hyperparam(\"eval_batch_size\")\n",
        "        hyperparam(\"eloss_coef\")\n",
        "        hyperparam(\"col_encode_rep\")\n",
        "        hyperparam(\"sch_step_epoch\")\n",
        "        hyperparam(\"grow_epoch\")\n",
        "        hyperparam(\"rebuild_tree_epoch\")\n",
        "        hyperparam(\"sample_per_box\")\n",
        "        hyperparam(\"sch_start_0\")\n",
        "        hyperparam(\"first_grow_epoch\")\n",
        "        hyperparam(\"last_grow_epoch\")\n",
        "        hyperparam(\"best_eval_res\")\n",
        "        hyperparam(\"conf_reg_coef\")\n",
        "\n",
        "    def debug_plot(name, pts, rgb):\n",
        "        logging.debug(name + \":\")\n",
        "        if pts is None:\n",
        "            logging.debug(\"No points\")\n",
        "            return\n",
        "        pts = pts.cpu()\n",
        "        rgb = torch.zeros_like(pts) + rgb.cpu()\n",
        "        rgb = rgb.clamp(min=0, max=1)\n",
        "        mask = torch.randperm(pts.shape[0])[:524288]\n",
        "        plot(pts[mask], rgb=rgb[mask], save=f\"./scratch/ns_{SCENE}_{CLOUD_NAME}_debug_{name}.png\")\n",
        "\n",
        "    if (resume_ckpt is None) or (\"postgrow\" not in resume_ckpt):\n",
        "        field.fix_norm_mesh_dir(\n",
        "            train_dataset.loader(batch_size=batch_size*2, shuffle=True, pin_memory=True, num_workers=7))\n",
        "        new_pts = field.pts\n",
        "        new_norm = field.pts_norm_mesh\n",
        "        mask = new_norm.norm(dim=-1) > 0.5\n",
        "        debug_plot(\"initial_norm_raw\", new_pts[mask], new_norm[mask]*0.5+0.5)\n",
        "    else:\n",
        "        logging.debug(\"postgrow loaded, skip initial fix dir\")\n",
        "\n",
        "\n",
        "    stat_ploss = Stat()\n",
        "    stat_eloss = Stat()\n",
        "    stat_psnr = Stat()\n",
        "\n",
        "    if eval_batch_size is None:\n",
        "        eval_batch_size = batch_size * 2\n",
        "\n",
        "    def create_ckpt():\n",
        "        return {\n",
        "            'epoch': epoch,\n",
        "            'field': field.state_dict(),\n",
        "            'opt': opt.state_dict(),\n",
        "            'sch': sch.state_dict(),\n",
        "            'best_eval_res': best_eval_res,\n",
        "        }\n",
        "\n",
        "    if start_epoch > 1:\n",
        "        train_loader = train_dataset.loader(batch_size=batch_size)\n",
        "        n = len(train_loader)\n",
        "        for i in range(1, start_epoch):\n",
        "            epoch = i\n",
        "            logging.info(f\"Skip warming up epoch #{i}\")\n",
        "            if first_grow_epoch <= epoch <= last_grow_epoch and epoch % grow_epoch == 0:\n",
        "                field.warmup_coef = 1\n",
        "                logging.info(f\"reset warmup coef to {field.warmup_coef}\")\n",
        "            for _ in range(n):\n",
        "                field.warmup_step(n)\n",
        "\n",
        "    for epoch in range(start_epoch, num_epoch + 1):\n",
        "        gc.collect()\n",
        "\n",
        "        if epoch > 0:\n",
        "\n",
        "            if first_grow_epoch <= epoch <= last_grow_epoch and epoch % grow_epoch == first_grow_epoch % grow_epoch:\n",
        "                logging.info(\"grow epoch\")\n",
        "\n",
        "                if epoch == start_epoch and (resume_ckpt is not None) and (\"postgrow\" in resume_ckpt):\n",
        "                    logging.info(\"loaded postgrow ckpt, skipping\")\n",
        "                    grow_pts = prune_pts = None\n",
        "                    new_pts = field.pts\n",
        "                    new_norm = field.pts_norm_mesh\n",
        "                else:\n",
        "                    ckpt = create_ckpt()\n",
        "                    torch.save(ckpt, f\"{OUTPUT}/{exp_name}_train_pregrow.ckpt\")\n",
        "                    logging.debug(f\"Saved pregrow\")\n",
        "                    grow_loader = grow_dataset.loader(batch_size=grow_batch_size, shuffle=True, pin_memory=True, num_workers=7)\n",
        "                    # grow_loader = Prefix(grow_loader, len(grow_loader) // 3)\n",
        "                    grow_pts, prune_pts, new_pts, new_norm = field.prune_and_grow(grow_loader, prune_outlier_fn)\n",
        "\n",
        "                field.fix_norm_mesh_dir(\n",
        "                    train_dataset.loader(batch_size=batch_size*2, shuffle=True, pin_memory=True, num_workers=7))\n",
        "                new_norm = field.pts_norm_mesh\n",
        "\n",
        "                debug_plot(f\"grow_points_{epoch}ep\", grow_pts, contour_rgb(grow_pts))\n",
        "                debug_plot(f\"prune_points_{epoch}ep\", prune_pts, contour_rgb(prune_pts))\n",
        "\n",
        "                from field.kd_field import fix_norm_direction\n",
        "                mask = new_norm.norm(dim=-1) > 0.5\n",
        "                debug_plot(f\"new_norm_raw_{epoch}ep\", new_pts[mask], new_norm[mask]*0.5+0.5)\n",
        "                new_norm = fix_norm_direction(new_norm, -torch.tensor(DEFAULT_VIEW_DIR).float().cuda())\n",
        "                debug_plot(f\"new_norm_{epoch}ep\", new_pts[mask], new_norm[mask]*0.5+0.5)\n",
        "\n",
        "                # if epoch == last_grow_epoch:\n",
        "                #     field.enable_st()\n",
        "\n",
        "                ckpt = create_ckpt()\n",
        "                torch.save(ckpt, f\"{OUTPUT}/{exp_name}_train_postgrow.ckpt\")\n",
        "                logging.debug(f\"Saved postgrow\")\n",
        "\n",
        "                del opt\n",
        "                del sch\n",
        "                gc.collect()\n",
        "                T = grow_sch_T if (first_grow_epoch <= epoch < last_grow_epoch) else sch_T\n",
        "                opt, sch = get_opt_sch(field, T)\n",
        "                field.warmup_coef = 1\n",
        "                logging.info(f\"reset warmup coef to {field.warmup_coef}\")\n",
        "\n",
        "            else:\n",
        "                # prune_mask = field.pts_prune()\n",
        "                # if prune_mask.sum().item() > 0:\n",
        "                #     prune_pts = field.pts[prune_mask]\n",
        "                # else:\n",
        "                #     prune_mask = None\n",
        "                #     prune_pts = None\n",
        "\n",
        "                # debug_plot(\"pseudo-prune points\", prune_pts, torch.tensor([1., 0., 0.]))\n",
        "                # field.pseudo_prune(prune_mask)\n",
        "\n",
        "                do_grow = False\n",
        "\n",
        "            samples = []\n",
        "            num_samples = 0\n",
        "\n",
        "            train_loader = train_dataset.loader(batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=7)\n",
        "            tbar = tqdm(train_loader, mininterval=5)\n",
        "            tbar.set_description(f\"Train #{epoch}\")\n",
        "\n",
        "            field.undeploy()\n",
        "\n",
        "            for index, (line_o, line_d, target) in enumerate(tbar):\n",
        "                assert field.training\n",
        "                line_o = line_o.cuda()\n",
        "                line_d = line_d.cuda()\n",
        "                target = target.cuda()\n",
        "                target, density_target = target.split([3, 1], dim=-1)\n",
        "\n",
        "                with logging_redirect_tqdm():\n",
        "                    pred_img, eloss, smp = field(line_o, line_d, sample_per_box=0)\n",
        "                    predict = field.field\n",
        "                    density_predict = field.density\n",
        "\n",
        "                ins = field.line_intersect\n",
        "                predict = predict[ins]\n",
        "                target = target[ins].float()\n",
        "                background = target.min(dim=-1).values < -0.5\n",
        "                target[background] += 4\n",
        "\n",
        "                density_predict = density_predict[ins]\n",
        "                density_target = density_target[ins].float()\n",
        "\n",
        "                # density_loss = img2mse(density_predict, density_target)\n",
        "\n",
        "                # predict[background] = predict[background] + (1 - density_predict[background]) * (\n",
        "                #                 target[background] - torch.tensor(BG_COLOR).float().cuda())\n",
        "\n",
        "                pred_img = pred_img[ins]\n",
        "                targ_img = target * density_target + field.default_field_val * (1 - density_target)\n",
        "                img_loss = img2mse(pred_img, targ_img)\n",
        "                field_loss = (predict - target.clamp(min=0, max=1)).pow(2).mean(dim=-1)\n",
        "                density_loss = (density_predict - density_target.clamp(min=0, max=1)).pow(2).reshape(-1)\n",
        "\n",
        "                sep_loss = field_loss * density_target.reshape(-1) + density_loss * (1 - density_target.reshape(-1)) + 0.1 * density_loss\n",
        "                if epoch < last_grow_epoch:\n",
        "                    ploss = img_loss + sep_loss\n",
        "                else:\n",
        "                    ploss = img_loss + 0.05 * sep_loss\n",
        "\n",
        "                ploss = ploss.mean()\n",
        "                eloss = eloss + (conf_reg_coef / eloss_coef) * field.conf_reg_loss\n",
        "                loss =  ploss + eloss_coef * eloss\n",
        "\n",
        "                assert not ploss.isnan().any()\n",
        "                assert not eloss.isnan().any()\n",
        "\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                # torch.nn.utils.clip_grad_norm_(field.parameters(), 1e-3, norm_type='inf', error_if_nonfinite=True)\n",
        "                opt.step()\n",
        "                last_lr = sch.get_last_lr()[0]\n",
        "                field.warmup_step(len(train_loader))\n",
        "\n",
        "                bs = ins.sum().item()\n",
        "                with torch.no_grad():\n",
        "                    stat_ploss.add(ploss, bs)\n",
        "                    stat_eloss.add(eloss, bs)\n",
        "                    stat_psnr.add(mse2psnr(img_loss), bs)\n",
        "\n",
        "                if index % 25 == 0:\n",
        "                    with torch.no_grad():\n",
        "                        conf = field.pts_conf()\n",
        "                        bad = (conf < 0.1).sum().item()\n",
        "                        logstr = f\"-{bad}, +{num_samples}, loss: {stat_ploss.preview():.4f} {stat_eloss.preview():.4f}, psnr: {stat_psnr.preview():.4f}\"\n",
        "                    tbar.set_postfix_str(logstr)\n",
        "                    if index % 500 == 0:\n",
        "                        with logging_redirect_tqdm():\n",
        "                            logging.info(f\"Train #{epoch} {index}/{len(tbar)} loss = {stat_ploss.preview():.4f} {stat_eloss.preview():.4f} psnr = {stat_psnr.preview():.4f}\")\n",
        "\n",
        "\n",
        "            if epoch % sch_step_epoch == 0:\n",
        "                sch.step()\n",
        "\n",
        "            if epoch % print_epoch == 0:\n",
        "                with torch.no_grad():\n",
        "                    conf = field.pts_conf()\n",
        "                    bad = (conf < 0.1).sum().item()\n",
        "\n",
        "                logging.info(f\"Train #{epoch} @{last_lr:.2e} \"\n",
        "                    + f\"loss = {stat_ploss} {stat_eloss.result():.4f} -{bad} +{num_samples} \"\n",
        "                    + f\"psnr = {stat_psnr} \"\n",
        "                )\n",
        "\n",
        "            # DEBUG ASSERT\n",
        "            assert not loss.isnan().any()\n",
        "            field.assert_no_nan(force=True)\n",
        "\n",
        "        if epoch % save_epoch == 0:\n",
        "\n",
        "            ckpt = create_ckpt()\n",
        "            torch.save(ckpt, f\"{OUTPUT}/{exp_name}_train_{epoch}ep.ckpt\")\n",
        "            logging.info(f\"Saved #{epoch}\")\n",
        "\n",
        "        if epoch % valid_epoch == 0:\n",
        "            eval_res_stat = evaluate(field, valid_dataset, norm_map=True,\n",
        "                                     show_sample=epoch <= 5 or epoch % show_epoch == 0,\n",
        "                                     batch_size=int(eval_batch_size * (\n",
        "                                         0.75 if field.pts.shape[0] > 0.5 * field.max_pts_lim else 1) + 0.5),\n",
        "                                     export_file=f\"{OUTPUT}/valid_images_{exp_name}_{epoch}ep.pth\")\n",
        "            eval_res = eval_res_stat.preview()\n",
        "            updated = \"\"\n",
        "            if eval_res > best_eval_res:\n",
        "                best_eval_res = eval_res\n",
        "                updated = \"updated\"\n",
        "                ckpt = create_ckpt()\n",
        "                torch.save(ckpt, f\"{OUTPUT}/{exp_name}_train_best.ckpt\")\n",
        "            logging.info(f\"Valid #{epoch} psnr = {eval_res_stat} {updated}\")\n",
        "\n",
        "            if epoch % save_epoch == 0:\n",
        "                ckpt = create_ckpt()\n",
        "                torch.save(ckpt, f\"{OUTPUT}/{exp_name}_train_{epoch}ep.ckpt\")\n",
        "                logging.info(f\"Saved #{epoch} (after valid)\")\n",
        "\n",
        "        if epoch > 0 and epoch % rebuild_tree_epoch == 0:\n",
        "            field.rebuild_trees()\n",
        "            logging.debug(\"Trees rebuilt\")\n",
        "\n",
        "            del opt\n",
        "            del sch\n",
        "            gc.collect()\n",
        "            T = grow_sch_T if (first_grow_epoch <= epoch < last_grow_epoch) else sch_T\n",
        "            opt, sch = get_opt_sch(field, T)\n",
        "\n",
        "        ckpt = create_ckpt()\n",
        "        torch.save(ckpt, f\"{OUTPUT}/{exp_name}_train_latest.ckpt\")\n",
        "        logging.debug(f\"Saved latest\")"
      ],
      "metadata": {
        "id": "hQMnwEK13nTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 1\n",
        "resume_ckpt = None"
      ],
      "metadata": {
        "id": "9PdmodizG2LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loop"
      ],
      "metadata": {
        "id": "7us8MfsE3qcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL = \"grow\"\n",
        "PREV_STAGE_LABEL = \"grow\""
      ],
      "metadata": {
        "id": "MbO3Q47QftjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ckpt_file = f\"./scratch/field_ns_{SCENE}_{CLOUD_NAME}_layer{MAX_LAYER}_{LABEL}_train_30ep.ckpt\"\n",
        "# start_epoch, ckpt = field.resume_ckpt(ckpt_file)\n",
        "# resume_ckpt = (ckpt_file, ckpt)\n",
        "# if (\"pregrow\" in ckpt_file) or (\"postgrow\" in ckpt_file):  start_epoch -= 1\n",
        "# evaluate(field, [], norm_map=True)"
      ],
      "metadata": {
        "id": "LHy2t6VHzjSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch"
      ],
      "metadata": {
        "id": "xOB8hZdXS1II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not eval_only:\n",
        "    # grow phase 1\n",
        "    if start_epoch <= 30:\n",
        "        train(field, f\"field_ns_{SCENE}_{CLOUD_NAME}_layer{MAX_LAYER}_{LABEL}\",\n",
        "            lr=2e-3, eloss_coef=1e-5,\n",
        "            conf_reg_coef=0.0002*TRAIN_REPEAT,\n",
        "            valid_epoch=2,\n",
        "            num_epoch=30,\n",
        "            sch_T=20, grow_sch_T_fact=1, grow_epoch_fact=1/20, rebuild_tree_fact=4,\n",
        "            start_epoch=start_epoch,\n",
        "            resume_ckpt=resume_ckpt,\n",
        "            first_grow_epoch=4, last_grow_epoch=12,\n",
        "            batch_size=4096*TRAIN_REPEAT, grow_batch_size=4096*TRAIN_REPEAT, eval_batch_size=4096)\n",
        "\n",
        "        start_epoch = 30 + 1\n",
        "        resume_ckpt = None\n",
        "\n",
        "    # grow phase 2\n",
        "    train(field, f\"field_ns_{SCENE}_{CLOUD_NAME}_layer{MAX_LAYER}_{LABEL}\",\n",
        "        lr=2e-3, eloss_coef=1e-5/2,\n",
        "        conf_reg_coef=0.0002/2*TRAIN_REPEAT,\n",
        "        valid_epoch=2,\n",
        "        num_epoch=70,\n",
        "        sch_T=40, grow_sch_T_fact=1, grow_epoch_fact=1/2, rebuild_tree_fact=4,\n",
        "        start_epoch=start_epoch,\n",
        "        resume_ckpt=resume_ckpt,\n",
        "        first_grow_epoch=31, last_grow_epoch=31,\n",
        "        batch_size=4096*TRAIN_REPEAT, grow_batch_size=4096*TRAIN_REPEAT, eval_batch_size=4096)"
      ],
      "metadata": {
        "id": "VhZKgdtmte_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval"
      ],
      "metadata": {
        "id": "sWl2wALFDhwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defs"
      ],
      "metadata": {
        "id": "m493V1SEoe5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from math import cos, sin"
      ],
      "metadata": {
        "id": "Ghlyz8wrp_LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=True, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = train_full_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "v9_l9nm3jfz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_full_imgs = []\n",
        "\n",
        "for i in tqdm(range(len(valid_config['frames']))):\n",
        "    o, d, a, eval_info = read_data_ns(valid_config, i, for_eval=True, full_image=True, ray_upsample=IMAGE_SCALE)\n",
        "    rayset = RayDataset(o, d, a)\n",
        "    valid_full_imgs.append([rayset, eval_info])\n",
        "\n",
        "valid_dataset = valid_full_dataset = ImageDataset(valid_full_imgs)\n",
        "print(len(valid_dataset))\n",
        "\n",
        "valid_subset = [valid_full_dataset[i] for i in range(0, 200, 20)]"
      ],
      "metadata": {
        "id": "-y8rTs9k7_QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mesh_norm(fix=True):\n",
        "    def debug_plot(name, pts, rgb):\n",
        "        logging.debug(name + \":\")\n",
        "        if pts is None:\n",
        "            logging.debug(\"No points\")\n",
        "            return\n",
        "        pts = pts.cpu()\n",
        "        rgb = torch.zeros_like(pts) + rgb.cpu()\n",
        "        rgb = rgb.clamp(min=0, max=1)\n",
        "        mask = torch.randperm(pts.shape[0])[:524288]\n",
        "        plot(pts[mask], rgb=rgb[mask])\n",
        "\n",
        "    from field.kd_field import fix_norm_direction\n",
        "    new_norm = field.pts_norm_mesh\n",
        "    if fix:\n",
        "        new_norm = fix_norm_direction(new_norm, -torch.tensor(DEFAULT_VIEW_DIR).float().cuda())\n",
        "    else:\n",
        "        new_norm = new_norm\n",
        "    mask = new_norm.norm(dim=-1) > 0.5\n",
        "    debug_plot(\"new norm\", field.pts[mask], new_norm[mask]*0.5+0.5)"
      ],
      "metadata": {
        "id": "FR2hMU2Zo3EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert not field.enable_space_transform"
      ],
      "metadata": {
        "id": "AsN0BBAkD_bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_PYgQKm41WiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# field.editting = True\n",
        "# field.orig_pts = field.pts.clone()\n",
        "# field.orig_unit_len = field.unit_len\n",
        "# field.orig_pts_norm_mesh = field.pts_norm_mesh.clone()\n",
        "# field.fixed_norm_mesh_dir = True\n",
        "# field.calculate_norm_mesh(remove_outlier=False)\n",
        "\n",
        "# M = field.estimate_initial_st()\n",
        "# M = M.reshape(-1, 3, 3)\n",
        "# M"
      ],
      "metadata": {
        "id": "dMNOUZ6t1WWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QslnprzMRjjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deform Init\n"
      ],
      "metadata": {
        "id": "juxcxGkInWub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    deform_pts = torch.load(f\"./datasets/Deform/{DEFORM}.{VER}.pth\")['pts'].float().cuda()\n",
        "except:\n",
        "    import numpy as np\n",
        "    deform_pts = np.load(f\"./datasets/Deform/{DEFORM}.{VER}.npy\")\n",
        "    deform_pts = torch.from_numpy(np.array(deform_pts)).float().cuda()\n",
        "\n",
        "plot(deform_pts, rgb=contour_rgb(deform_pts))\n",
        "deform_pts.shape"
      ],
      "metadata": {
        "id": "jvOzpqaknWub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_file = f\"./datasets/Models/scene_edit/{SCENE}.{VER}.ckpt\"\n",
        "start_epoch, ckpt = field.resume_ckpt(ckpt_file)\n",
        "\n",
        "assert field.pts.shape == deform_pts.shape"
      ],
      "metadata": {
        "id": "-xb2YYZTnWuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.fix_norm_mesh_dir(\n",
        "    Prefix(train_dataset.loader(batch_size=8192, shuffle=True, pin_memory=True, num_workers=7), ratio=0.1))\n",
        "plot_mesh_norm(fix=False)"
      ],
      "metadata": {
        "id": "mdWEGXX3nWuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = f\"./datasets/Deform/{DEFORM}_data\"\n",
        "train_config = json.load(open(f\"{DATASET}/views_train/transforms.json\"))\n",
        "grow_extra_config = None #json.load(open(f\"{DATASET}/transforms_val.json\"))\n",
        "prune_extra_config = None\n",
        "valid_config = json.load(open(f\"{DATASET}/views_test/transforms.json\"))"
      ],
      "metadata": {
        "id": "zfb8K1txnWuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=True, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "h9VtCJC6BwMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.init_pts(deform_pts, editting=True)\n",
        "field.enable_st()"
      ],
      "metadata": {
        "id": "KPSOlHQOx5MO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.fix_norm_mesh_dir(\n",
        "    Prefix(train_dataset.loader(batch_size=8192, shuffle=True, pin_memory=True, num_workers=7), ratio=0.1))\n",
        "plot_mesh_norm(fix=False)"
      ],
      "metadata": {
        "id": "12KD6x4PBxPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFORM_CKPT = f\"./scratch/deform_{DEFORM}_init.ckpt\"\n",
        "torch.save(field.state_dict(), DEFORM_CKPT)"
      ],
      "metadata": {
        "id": "IWW1orofx5tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deform Full"
      ],
      "metadata": {
        "id": "Te1IEuk-xndJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "field.load_state_dict(torch.load(DEFORM_CKPT))\n",
        "field.naive_plot_mode = False\n",
        "field.init_space_transform = True"
      ],
      "metadata": {
        "id": "A6s2eDqKybzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=True, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "jgVq-ZFOnWuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_full_imgs = []\n",
        "\n",
        "for i in tqdm(range(len(valid_config['frames']))):\n",
        "    o, d, a, eval_info = read_data_ns(valid_config, i, for_eval=True, full_image=True, ray_upsample=IMAGE_SCALE)\n",
        "    rayset = RayDataset(o, d, a)\n",
        "    valid_full_imgs.append([rayset, eval_info])\n",
        "\n",
        "valid_dataset = valid_full_dataset = ImageDataset(valid_full_imgs)\n",
        "print(len(valid_dataset))\n",
        "\n",
        "valid_subset = [valid_full_dataset[i] for i in range(0, len(valid_dataset), 10)]"
      ],
      "metadata": {
        "id": "IuSy8UlmnWuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.enable_st(reinit=True)\n",
        "field.train_st(\n",
        "    Prefix(train_dataset.loader(batch_size=8192, shuffle=True, pin_memory=True, num_workers=7), ratio=0.1), num_epoch=1)"
      ],
      "metadata": {
        "id": "ABibS7dZnWuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(field, valid_subset, inpaint=False, show_all=True, show_predict_only=False, norm_map=False))"
      ],
      "metadata": {
        "id": "eMLx2ZXJnWuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=False, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "3z9OchXTnWud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.warmup_coef = 1e-4\n",
        "field.warmup_mult = 1e-4\n",
        "train(field, f\"field_ns_deform_{DEFORM}\",\n",
        "    lr=2e-3, eloss_coef=1e-5,\n",
        "    conf_reg_coef=0.0002,\n",
        "    valid_epoch=1,\n",
        "    num_epoch=1,\n",
        "    sch_T=6, grow_sch_T_fact=1, grow_epoch_fact=1/6, rebuild_tree_fact=4,\n",
        "    start_epoch=0,\n",
        "    resume_ckpt=None,\n",
        "    first_grow_epoch=0, last_grow_epoch=0,\n",
        "    # batch_size=3072, grow_batch_size=3072, eval_batch_size=4096)\n",
        "    batch_size=4096, grow_batch_size=4096, eval_batch_size=4096)"
      ],
      "metadata": {
        "id": "-C_fVTXWnWud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(field, valid_subset, inpaint=False, show_all=True, show_predict_only=False, norm_map=False))"
      ],
      "metadata": {
        "id": "J0LUoxK2nWud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deform Naive\n"
      ],
      "metadata": {
        "id": "x7r-XXgugTCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "field.load_state_dict(torch.load(DEFORM_CKPT))\n",
        "field.naive_plot_mode = True\n",
        "field.init_space_transform = False"
      ],
      "metadata": {
        "id": "LbnHrqaqgVU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=True, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "M6t-anCZgTCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_full_imgs = []\n",
        "\n",
        "for i in tqdm(range(len(valid_config['frames']))):\n",
        "    o, d, a, eval_info = read_data_ns(valid_config, i, for_eval=True, full_image=True, ray_upsample=IMAGE_SCALE)\n",
        "    rayset = RayDataset(o, d, a)\n",
        "    valid_full_imgs.append([rayset, eval_info])\n",
        "\n",
        "valid_dataset = valid_full_dataset = ImageDataset(valid_full_imgs)\n",
        "print(len(valid_dataset))\n",
        "\n",
        "valid_subset = [valid_full_dataset[i] for i in range(0, len(valid_dataset), 10)]"
      ],
      "metadata": {
        "id": "AJNQTcp5gTCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.enable_st(reinit=True)\n",
        "field.train_st(\n",
        "    Prefix(train_dataset.loader(batch_size=8192, shuffle=True, pin_memory=True, num_workers=7), ratio=0.1), num_epoch=1)"
      ],
      "metadata": {
        "id": "XFBGqfK4gTCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(field, valid_subset, inpaint=False, show_all=True, show_predict_only=False, norm_map=False))"
      ],
      "metadata": {
        "id": "8ld0Zk0jgTCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=False, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "sAiuxxUMgTCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.warmup_coef = 1e-4\n",
        "field.warmup_mult = 1e-4\n",
        "train(field, f\"field_ns_deform_{DEFORM}_naive\",\n",
        "    lr=2e-3, eloss_coef=1e-5,\n",
        "    conf_reg_coef=0.0002,\n",
        "    valid_epoch=1,\n",
        "    num_epoch=1,\n",
        "    sch_T=6, grow_sch_T_fact=1, grow_epoch_fact=1/6, rebuild_tree_fact=4,\n",
        "    start_epoch=0,\n",
        "    resume_ckpt=None,\n",
        "    first_grow_epoch=0, last_grow_epoch=0,\n",
        "    # batch_size=3072, grow_batch_size=3072, eval_batch_size=4096)\n",
        "    batch_size=4096, grow_batch_size=4096, eval_batch_size=4096)"
      ],
      "metadata": {
        "id": "i7Dx83qfgTCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(field, valid_subset, inpaint=False, show_all=True, show_predict_only=False, norm_map=False))"
      ],
      "metadata": {
        "id": "7Wi1GwOOgTCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deform NoInitSt\n"
      ],
      "metadata": {
        "id": "PsiHf6hrTr2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "field.load_state_dict(torch.load(DEFORM_CKPT))\n",
        "field.naive_plot_mode = False\n",
        "field.init_space_transform = False"
      ],
      "metadata": {
        "id": "ap8ym2YRTr2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=True, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "qi7-k9vcTr2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_full_imgs = []\n",
        "\n",
        "for i in tqdm(range(len(valid_config['frames']))):\n",
        "    o, d, a, eval_info = read_data_ns(valid_config, i, for_eval=True, full_image=True, ray_upsample=IMAGE_SCALE)\n",
        "    rayset = RayDataset(o, d, a)\n",
        "    valid_full_imgs.append([rayset, eval_info])\n",
        "\n",
        "valid_dataset = valid_full_dataset = ImageDataset(valid_full_imgs)\n",
        "print(len(valid_dataset))\n",
        "\n",
        "valid_subset = [valid_full_dataset[i] for i in range(0, len(valid_dataset), 10)]"
      ],
      "metadata": {
        "id": "_kw4tFd5Tr2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.enable_st(reinit=True)\n",
        "field.train_st(\n",
        "    Prefix(train_dataset.loader(batch_size=8192, shuffle=True, pin_memory=True, num_workers=7), ratio=0.1), num_epoch=1)"
      ],
      "metadata": {
        "id": "YjEHRrDgTr2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(field, valid_subset, inpaint=False, show_all=True, show_predict_only=False, norm_map=False))"
      ],
      "metadata": {
        "id": "eqfSr28OTr2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_o = []\n",
        "train_fn = []\n",
        "\n",
        "for i in tqdm(range(len(train_config['frames']))):\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    o, fn, ofn = read_data_ns(train_config, i, ray_upsample=1, full_image=False, return_fn=True)\n",
        "    train_o.append(o)\n",
        "    train_fn.append(fn)\n",
        "\n",
        "train_o = torch.cat(train_o * TRAIN_REPEAT, dim=0)\n",
        "train_fn = train_fn * TRAIN_REPEAT\n",
        "\n",
        "train_dataset = RayDataset(train_o, fn=train_fn)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "id": "GsI5VuofTr2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field.warmup_coef = 1e-4\n",
        "field.warmup_mult = 1e-4\n",
        "train(field, f\"field_ns_deform_{DEFORM}_noinitst\",\n",
        "    lr=2e-3, eloss_coef=1e-5,\n",
        "    conf_reg_coef=0.0002,\n",
        "    valid_epoch=1,\n",
        "    num_epoch=1,\n",
        "    sch_T=6, grow_sch_T_fact=1, grow_epoch_fact=1/6, rebuild_tree_fact=4,\n",
        "    start_epoch=0,\n",
        "    resume_ckpt=None,\n",
        "    first_grow_epoch=0, last_grow_epoch=0,\n",
        "    # batch_size=3072, grow_batch_size=3072, eval_batch_size=4096)\n",
        "    batch_size=4096, grow_batch_size=4096, eval_batch_size=4096)"
      ],
      "metadata": {
        "id": "8wI1xGtXTr2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(field, valid_subset, inpaint=False, show_all=True, show_predict_only=False, norm_map=False))"
      ],
      "metadata": {
        "id": "jWp-WzogTr2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "oLtuK2ux2sJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert False"
      ],
      "metadata": {
        "id": "4nTdTHaOAd3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oz = -math.pi / 2\n",
        "oz = torch.tensor([\n",
        "    [cos(oz), -sin(oz), 0],\n",
        "    [sin(oz), cos(oz), 0],\n",
        "    [0, 0, 1]\n",
        "]).float().cuda()\n",
        "\n",
        "oz"
      ],
      "metadata": {
        "id": "LYUSaSdCnWig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2z99zgrTycwm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}